# WebUnlock 1.0 ‚Äì MVP

Transforme elementos de p√°ginas web em **APIs JSON** usando **Puppeteer** e uma interface web simples, moderna e auto‚Äëhosteada.

Este reposit√≥rio cont√©m:

- **M√≥dulo de scraping** (`src/scraper.js`) usando Puppeteer.
- **API HTTP** (`server.js`) em Express expondo a rota `/scrape`.
- **Interface Web** (`public/`) para testar o scraping visualmente.

---

## Requisitos

- **Node.js** 18+ (recomendado 18 ou 20).
- Acesso √† internet (para fazer o scraping das p√°ginas de destino).

---

## Instala√ß√£o

1. **Clonar ou copiar o projeto** para sua m√°quina.
2. No terminal, navegar at√© a pasta do projeto:

```bash
cd "C:\Users\Elisio da Silva\Desktop\Coisas do Jo√£o\WebUnlock1.0"
```

3. **Instalar depend√™ncias**:

```bash
npm install
```

Isso instalar√°, entre outros:

- `express` ‚Äì servidor HTTP.
- `puppeteer` ‚Äì controle do Chromium para fazer o scraping.

> Observa√ß√£o: o Puppeteer pode baixar automaticamente uma vers√£o do Chromium na primeira instala√ß√£o. Esse passo pode demorar alguns minutos.

---

## Como startar o projeto

1. Certifique‚Äëse de estar na pasta raiz do projeto:

```bash
cd "C:\Users\....\WebUnlock1.0"
```

2. Inicie o servidor em modo desenvolvimento/local:

```bash
npm start
```

3. Se tudo estiver correto, o terminal deve exibir algo como:

```text
WebUnlock rodando em http://localhost:3000
```

4. Abra o navegador e acesse:

```text
http://localhost:3000
```

---

## Interface Web (Frontend)

Arquivos principais na pasta `public/`:

- `index.html` ‚Äì p√°gina principal com o formul√°rio.
- `styles.css` ‚Äì estilos da interface (tema escuro, layout responsivo).
- `app.js` ‚Äì l√≥gica de front para chamar a API `/scrape` e exibir o resultado.

### Como usar a interface

1. Com o servidor rodando (`npm start`), abra `http://localhost:3000` no navegador.
2. No formul√°rio, preencha:
   - **URL da p√°gina** ‚Äì ex.: `https://g1.globo.com/`
   - **Seletor CSS do elemento** ‚Äì ex.: `h1`, `.classe`, `#id`.
3. Clique em **‚ÄúExecutar scrape‚Äù**.
4. O painel de resultado √† direita mostrar√° um JSON semelhante a:

```json
{
  "success": true,
  "url": "https://g1.globo.com/",
  "selector": "h1",
  "data": "T√≠tulo principal da p√°gina..."
}
```

5. Use o bot√£o **‚ÄúCopiar‚Äù** para copiar o JSON exibido para a √°rea de transfer√™ncia.

---

## API HTTP (Backend)

O backend principal est√° em `server.js`, usando Express.

### Rotas dispon√≠veis

- **GET `/health`**

  - Verifica se o servi√ßo est√° de p√©.
  - Exemplo de resposta:

  ```json
  {
    "status": "ok",
    "service": "WebUnlock",
    "timestamp": "2026-01-27T12:34:56.789Z"
  }
  ```

- **POST `/scrape`**

  - Corpo esperado (JSON):

  ```json
  {
    "url": "https://exemplo.com",
    "selector": "h1"
  }
  ```

  - Resposta de sucesso:

  ```json
  {
    "success": true,
    "url": "https://exemplo.com",
    "selector": "h1",
    "data": "Texto encontrado no elemento"
  }
  ```

  - Em caso de erro de par√¢metros (faltando `url` ou `selector`):

  ```json
  {
    "success": false,
    "error": "Par√¢metros inv√°lidos. Envie \"url\" e \"selector\"."
  }
  ```

> Importante: Mesmo em caso de falha de scraping interna, o contrato da fun√ß√£o `scrapeElement` retorna `null` em `data`, e o Express responde com `success: true` + `data: null`. Os detalhes do erro s√£o logados no console do servidor.

---

## M√≥dulo de Scraping (`src/scraper.js`)

O m√≥dulo usa **Puppeteer** para abrir a p√°gina e extrair o texto de um √∫nico elemento CSS.

### Fun√ß√£o principal

- **Assinatura**:

```js
async function scrapeElement(url, selector): Promise<string | null>
```

- **Comportamento**:
  - Abre um navegador headless (`headless: 'new'`) com flags otimizadas para ambiente de servidor.
  - Faz `page.goto(url, { waitUntil: 'domcontentloaded' })`.
  - Aguarda o seletor (`page.waitForSelector(selector, { timeout: 10000 })`).
  - Dentro de `page.evaluate`:
    - Tenta `element.innerText.trim()`.
    - Se vazio, tenta `element.textContent.trim()`.
    - Se n√£o encontrar o elemento ou n√£o houver texto, retorna `null`.
  - Usa `try/catch/finally`:
    - Loga erros no console incluindo `url` e `selector`.
    - Garante `browser.close()` no bloco `finally`.

### Uso direto em Node (sem Express)

Voc√™ pode usar o m√≥dulo diretamente em qualquer script Node:

```js
const { scrapeElement } = require('./src/scraper');

(async () => {
  const url = 'https://example.com';
  const selector = 'h1';

  const text = await scrapeElement(url, selector);
  console.log('Resultado do scrape:', text);
})();
```

---

## Script de teste r√°pido (`test-scraper.js`)

Al√©m da interface web, h√° um script simples para testar o scraper via terminal:

```js
const { scrapeElement } = require('./src/scraper');

(async () => {
  const url = 'https://g1.globo.com/';
  const selector = 'p';

  const text = await scrapeElement(url, selector);
  console.log('Resultado do scrape:', text);
  process.exit(0);
})();
```

### Como rodar o teste

```bash
cd "C:\Users\Elisio da Silva\Desktop\Coisas do Jo√£o\WebUnlock1.0"
node test-scraper.js
```

---

## Pr√≥ximos passos poss√≠veis (id√©ias de evolu√ß√£o)

- Aceitar **v√°rios seletores** e retornar um objeto JSON com v√°rios campos.
- Suporte a **templates de scraping** salvos (para reusar ‚ÄúAPIs‚Äù por site).
- Autentica√ß√£o b√°sica (token simples) para expor isso como um **SaaS** real.
- Filas/queue para lidar com alto volume de requisi√ß√µes.

Este MVP j√° √© suficiente para brincar com o conceito de **‚Äúsites como APIs JSON‚Äù** localmente. Sinta‚Äëse √† vontade para adaptar, refatorar e evoluir para o produto final. üòâ

